{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "import random\n",
    "import string\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np  # linear algebra\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as Fun\n",
    "import torchvision.transforms as T\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import models\n",
    "from tqdm import trange\n",
    "\n",
    "# TRAIN_PATH = \"./train\"\n",
    "# TEST_PATH  = \"./test\"\n",
    "TRAIN_PATH = \"/kaggle/input/captcha-hacker/train\"\n",
    "TEST_PATH  = \"/kaggle/input/captcha-hacker/test\"\n",
    "\n",
    "class_index = dict(zip(string.ascii_lowercase+string.digits, range(36)))\n",
    "class_index_rev = dict(zip(range(36), string.ascii_lowercase+string.digits))\n",
    "print(class_index)\n",
    "print(class_index_rev)\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "# device = 'cpu'\n",
    "print(f\"current using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = []\n",
    "val_data = []\n",
    "\n",
    "with open(f'{TRAIN_PATH}/annotations.csv', newline='') as csvfile:\n",
    "    for row in csv.reader(csvfile, delimiter=','):\n",
    "        if random.random() < 0.7:\n",
    "            train_data.append(row)\n",
    "        else:\n",
    "            val_data.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function\n",
    "def rotate_img(img, angle):\n",
    "    height, width = img.shape[:2]\n",
    "    # 使用 cv2.getRotationMatrix2D() 函式計算旋轉矩陣\n",
    "    # getRptationMatrix2D(center, angle(+/-), zoom rate)\n",
    "    M = cv2.getRotationMatrix2D((width // 2, height // 2), angle, 1)\n",
    "\n",
    "    # 使用 cv2.warpAffine() 函式對圖片進行旋轉\n",
    "    img_rotated = cv2.warpAffine(img, M, (width, height))\n",
    "    return img_rotated\n",
    "def InjectNoise(img, std):\n",
    "    noise = np.zeros_like(img, dtype=np.float32)\n",
    "    cv2.randn(noise, 0, std)\n",
    "    img = (img+noise)\n",
    "    img[np.where(img > 255)] = 255\n",
    "    img[np.where(img < 0)] = 0\n",
    "    return img\n",
    "\n",
    "def DataAugmentation(x_train, y_train):\n",
    "    aug_number = 5\n",
    "    rotate_angle = [30, 60, -30, -60]\n",
    "    x_train_aug = np.zeros(shape=(len(x_train) * aug_number, 64, 64, 3), dtype=np.uint8)\n",
    "    y_train_aug = np.zeros(shape=(len(y_train) * aug_number, len(y_train[0])), dtype=np.int64)\n",
    "    for i in trange(0, len(x_train) * aug_number, aug_number):\n",
    "        index = i // aug_number\n",
    "        y_train_aug[i : i + aug_number] = y_train[index]\n",
    "        x_train_aug[i] = x_train[index]\n",
    "        x_train_aug[i + 1] = rotate_img(x_train[index], rotate_angle[0])\n",
    "        x_train_aug[i + 2] = rotate_img(x_train[index], rotate_angle[1])\n",
    "        x_train_aug[i + 3] = rotate_img(x_train[index], rotate_angle[2])\n",
    "        x_train_aug[i + 4] = rotate_img(x_train[index], rotate_angle[3])\n",
    "    return np.array(x_train_aug), np.array(y_train_aug)\n",
    "\n",
    "def read_data(rows, prefix, root):\n",
    "    filenames = np.array([sample for sample in rows if sample[0].startswith(prefix)])\n",
    "    imgs = filenames[:, 0]\n",
    "    label = filenames[:, 1]\n",
    "    images = np.zeros(shape=(len(filenames), 64, 64, 3), dtype=np.uint8)\n",
    "    labels = np.zeros(shape=(len(filenames), len(label[0])), dtype=np.int32)\n",
    "    for i in trange(len(filenames)):\n",
    "        curr_img = cv2.imread(f\"{root}/{imgs[i]}\")\n",
    "        curr_img = cv2.resize(curr_img,  (64, 64))\n",
    "#         curr_img = np.mean(curr_img, axis=2)\n",
    "        images[i] = curr_img\n",
    "        if prefix == \"task1\":\n",
    "            curr_label = [class_index[x]-26 for x in label[i]]\n",
    "        else:\n",
    "            curr_label = [class_index[x] for x in label[i]]\n",
    "        labels[i] = np.array(curr_label)\n",
    "    return np.array(imgs), np.array(images), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImgDataset(Dataset):\n",
    "    def __init__(self, x_data, y_data, root, filenames, return_filename=False, prefix=\"task1\"):\n",
    "        x_data = x_data.astype('float32')\n",
    "        self.x_data = torch.from_numpy(x_data).permute(0, 3, 1, 2) # (N, 1, 32, 32)\n",
    "        self.y_data = torch.from_numpy(y_data) # (N, 1)\n",
    "        self.filenames = filenames\n",
    "        self.return_filename = return_filename\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        if self.return_filename:\n",
    "            return self.x_data[index], self.filenames[index] # aug_num = 5\n",
    "        else:\n",
    "            return self.x_data[index], self.y_data[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all data\n",
    "# filename to image\n",
    "train_data_path, x_train, y_train = read_data(rows=train_data, prefix=\"task1\", root=TRAIN_PATH)\n",
    "val_data_path, x_val, y_val = read_data(rows=val_data, prefix=\"task1\", root=TRAIN_PATH)\n",
    "x_train_aug, y_train_aug = DataAugmentation(x_train, y_train)\n",
    "\n",
    "train_ds1 = ImgDataset(x_data=x_train_aug, y_data=y_train_aug, root=TRAIN_PATH, filenames=train_data, return_filename=False, prefix=\"task1\")\n",
    "train_dl1 = DataLoader(train_ds1, batch_size=500, num_workers=2, shuffle=True)\n",
    "\n",
    "val_ds1 = ImgDataset(x_data=x_val, y_data=y_val, root=TRAIN_PATH, filenames=val_data, return_filename=False, prefix=\"task1\")\n",
    "val_dl1 = DataLoader(val_ds1, batch_size=500, num_workers=2, shuffle=True)\n",
    "\n",
    "print(\"Data1 Done\")\n",
    "train_data_path, x_train, y_train = read_data(rows=train_data, prefix=\"task2\", root=TRAIN_PATH)\n",
    "val_data_path, x_val, y_val = read_data(rows=val_data, prefix=\"task2\", root=TRAIN_PATH)\n",
    "x_train_aug, y_train_aug = DataAugmentation(x_train, y_train)\n",
    "\n",
    "train_ds2 = ImgDataset(x_data=x_train_aug, y_data=y_train_aug, root=TRAIN_PATH, filenames=train_data, return_filename=False, prefix=\"task2\")\n",
    "train_dl2 = DataLoader(train_ds2, batch_size=500, num_workers=2, shuffle=True)\n",
    "\n",
    "val_ds2 = ImgDataset(x_data=x_val, y_data=y_val, root=TRAIN_PATH, filenames=val_data, return_filename=False, prefix=\"task2\")\n",
    "val_dl2 = DataLoader(val_ds2, batch_size=500, num_workers=2, shuffle=True)\n",
    "\n",
    "print(\"Data2 Done\")\n",
    "\n",
    "# filename to image\n",
    "train_data_path, x_train, y_train = read_data(rows=train_data, prefix=\"task3\", root=TRAIN_PATH)\n",
    "val_data_path, x_val, y_val = read_data(rows=val_data, prefix=\"task3\", root=TRAIN_PATH)\n",
    "x_train_aug, y_train_aug = DataAugmentation(x_train, y_train)\n",
    "\n",
    "train_ds3 = ImgDataset(x_data=x_train_aug, y_data=y_train_aug, root=TRAIN_PATH, filenames=train_data, return_filename=False, prefix=\"task3\")\n",
    "train_dl3 = DataLoader(train_ds3, batch_size=500, num_workers=2, shuffle=True)\n",
    "\n",
    "val_ds3 = ImgDataset(x_data=x_val, y_data=y_val, root=TRAIN_PATH, filenames=val_data, return_filename=False, prefix=\"task3\")\n",
    "val_dl3 = DataLoader(val_ds3, batch_size=500, num_workers=2, shuffle=True)\n",
    "print(\"Data3 Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Mymodel1(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Mymodel1, self).__init__()\n",
    "\n",
    "        self.model = models.resnet18(pretrained=True)\n",
    "\n",
    "    # for param in self.model.parameters():\n",
    "      # param.requires_grad = False\n",
    "\n",
    "        self.model.fc = nn.Linear(512, 10)\n",
    "    def forward(self, x):\n",
    "        logits = self.model(x)\n",
    "        return logits\n",
    "model1 = Mymodel1().to(device)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model1.parameters(), lr=1e-3)\n",
    "\n",
    "for epoch in range(30):\n",
    "    print(f\"Epoch [{epoch}]\")\n",
    "    model1.train()\n",
    "    for images, label in train_dl1:\n",
    "        images, label = images.to(device), label.to(device)\n",
    "        output = model1(images)\n",
    "        \n",
    "        loss = loss_fn(output, label.squeeze(1))\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    sample_count = 0\n",
    "    correct_count = 0\n",
    "    model1.eval()\n",
    "    for image, label in val_dl1:\n",
    "        image, label = image.to(device), label.to(device)\n",
    "        # predict and get prediction for each char\n",
    "        output = model1(image)\n",
    "        pred = torch.argmax(output, dim=1)\n",
    "        label = label.squeeze(1)\n",
    "        sample_count += len(image)\n",
    "        correct_count += (pred == label).sum()\n",
    "        final_acc1 = correct_count / sample_count\n",
    "    print(\"Model1 accuracy (validation):\", final_acc1)\n",
    "print(\"Task1 done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mymodel2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Mymodel2, self).__init__()\n",
    "\n",
    "        self.model = models.resnet18(pretrained=True)\n",
    "\n",
    "    # for param in self.model.parameters():\n",
    "      # param.requires_grad = False\n",
    "        num_ftrs = self.model.fc.in_features\n",
    "        self.model.fc = nn.Identity()\n",
    "        self.fc1 = nn.Linear(num_ftrs, 36)\n",
    "        self.fc2 = nn.Linear(num_ftrs, 36)\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        out1 = self.fc1(x)\n",
    "        out2 = self.fc2(x)\n",
    "        return out1, out2        \n",
    "model2 = Mymodel2().to(device)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model2.parameters(), lr=1e-3)\n",
    "final_acc2 = 0\n",
    "\n",
    "for epoch in range(40):\n",
    "    print(f\"Epoch [{epoch}]\")\n",
    "    model2.train()\n",
    "    for images, label in train_dl2:\n",
    "        images, label = images.to(device), label.to(device)\n",
    "        output = model2(images)\n",
    "        loss1 = loss_fn(output[0], label[:, 0])\n",
    "        loss2 = loss_fn(output[1], label[:, 1])\n",
    "        loss = loss1 + loss2\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    sample_count = 0\n",
    "    correct_count = 0\n",
    "    model2.eval()\n",
    "    for image, label in val_dl2:\n",
    "        image, label = image.to(device), label.to(device)\n",
    "        # predict and get prediction for each char\n",
    "        output = model2(image)\n",
    "        pred1 = torch.argmax(output[0], dim=1)\n",
    "        pred2 = torch.argmax(output[1], dim=1)\n",
    "        sample_count += len(image)*2\n",
    "        correct_count += (pred1 == label[:, 0]).sum()\n",
    "        correct_count += (pred2 == label[:, 1]).sum()\n",
    "        final_acc2 = correct_count / sample_count\n",
    "    print(\"Model2 accuracy (validation):\", final_acc2)\n",
    "print(\"Task2 Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mymodel3(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Mymodel3, self).__init__()\n",
    "\n",
    "        self.model = models.resnet18(pretrained=True)\n",
    "\n",
    "    # for param in self.model.parameters():\n",
    "      # param.requires_grad = False\n",
    "\n",
    "        num_ftrs = self.model.fc.in_features\n",
    "        self.model.fc = nn.Identity()\n",
    "        self.fc1 = nn.Linear(num_ftrs, 36)\n",
    "        self.fc2 = nn.Linear(num_ftrs, 36)\n",
    "        self.fc3 = nn.Linear(num_ftrs, 36)\n",
    "        self.fc4 = nn.Linear(num_ftrs, 36)\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        logits1 = self.fc1(x)\n",
    "        logits2 = self.fc2(x)\n",
    "        logits3 = self.fc3(x)\n",
    "        logits4 = self.fc4(x)\n",
    "        return logits1, logits2, logits3, logits4\n",
    "model3 = Mymodel3().to(device)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model3.parameters(), lr=4e-3)\n",
    "final_acc3 = 0\n",
    "for epoch in range(50):\n",
    "    print(f\"Epoch [{epoch}]\")\n",
    "    model3.train()\n",
    "    for images, label in train_dl3:\n",
    "        images, label = images.to(device), label.to(device)\n",
    "        output = model3(images)\n",
    "        \n",
    "        loss1 = loss_fn(output[0], label[:, 0])\n",
    "        loss2 = loss_fn(output[1], label[:, 1])\n",
    "        loss3 = loss_fn(output[2], label[:, 2])\n",
    "        loss4 = loss_fn(output[3], label[:, 3])\n",
    "        loss = loss1 + loss2 + loss3 + loss4\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    sample_count = 0\n",
    "    correct_count = 0\n",
    "    model3.eval()\n",
    "    for image, label in val_dl3:\n",
    "        image, label = image.to(device), label.to(device)\n",
    "        # predict and get prediction for each char\n",
    "        output = model3(image)\n",
    "        pred1 = torch.argmax(output[0], dim=1)\n",
    "        pred2 = torch.argmax(output[1], dim=1)\n",
    "        pred3 = torch.argmax(output[2], dim=1)\n",
    "        pred4 = torch.argmax(output[3], dim=1)\n",
    "        sample_count += len(image)*4\n",
    "        correct_count += (pred1 == label[:, 0]).sum()\n",
    "        correct_count += (pred2 == label[:, 1]).sum()\n",
    "        correct_count += (pred3 == label[:, 2]).sum()\n",
    "        correct_count += (pred4 == label[:, 3]).sum()\n",
    "        final_acc3 = correct_count / sample_count\n",
    "    print(\"Model3 accuracy (validation):\", final_acc3)\n",
    "print(\"Task3 Done\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

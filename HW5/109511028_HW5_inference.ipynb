{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import\n",
    "import csv\n",
    "import os\n",
    "import random\n",
    "import string\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np  # linear algebra\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as Fun\n",
    "import torchvision.transforms as T\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import models\n",
    "from tqdm import trange\n",
    "\n",
    "TEST_PATH = \"/content/drive/MyDrive/data/test\"\n",
    "# TRAIN_PATH = \"/kaggle/input/captcha-hacker/train\"\n",
    "# TEST_PATH  = \"/kaggle/input/captcha-hacker/test\"\n",
    "\n",
    "class_index = dict(zip(string.ascii_lowercase+string.digits, range(36)))\n",
    "class_index_rev = dict(zip(range(36), string.ascii_lowercase+string.digits))\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "# device = 'cpu'\n",
    "print(f\"current using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Architecture of my model\n",
    "class Mymodel1(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Mymodel1, self).__init__()\n",
    "\n",
    "        # self.model = models.resnet18(pretrained=True)\n",
    "        self.model = models.resnet18(weights='ResNet50_Weights.DEFAULT')\n",
    "\n",
    "    # for param in self.model.parameters():\n",
    "      # param.requires_grad = False\n",
    "\n",
    "        self.model.fc = nn.Linear(512, 10)\n",
    "    def forward(self, x):\n",
    "        logits = self.model(x)\n",
    "        return logits\n",
    "class Mymodel2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Mymodel2, self).__init__()\n",
    "\n",
    "        # self.model = models.resnet18(pretrained=True)\n",
    "        self.model = models.resnet18(weights='ResNet50_Weights.DEFAULT')\n",
    "\n",
    "    # for param in self.model.parameters():\n",
    "      # param.requires_grad = False\n",
    "        num_ftrs = self.model.fc.in_features\n",
    "        self.model.fc = nn.Identity()\n",
    "        self.fc1 = nn.Linear(num_ftrs, 36)\n",
    "        self.fc2 = nn.Linear(num_ftrs, 36)\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        out1 = self.fc1(x)\n",
    "        out2 = self.fc2(x)\n",
    "        return out1, out2        \n",
    "class Mymodel3(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Mymodel3, self).__init__()\n",
    "\n",
    "        # self.model = models.resnet18(pretrained=True)\n",
    "        self.model = models.resnet18(weights='ResNet50_Weights.DEFAULT')\n",
    "\n",
    "    # for param in self.model.parameters():\n",
    "      # param.requires_grad = False\n",
    "\n",
    "        num_ftrs = self.model.fc.in_features\n",
    "        self.model.fc = nn.Identity()\n",
    "        self.fc1 = nn.Linear(num_ftrs, 36)\n",
    "        self.fc2 = nn.Linear(num_ftrs, 36)\n",
    "        self.fc3 = nn.Linear(num_ftrs, 36)\n",
    "        self.fc4 = nn.Linear(num_ftrs, 36)\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        logits1 = self.fc1(x)\n",
    "        logits2 = self.fc2(x)\n",
    "        logits3 = self.fc3(x)\n",
    "        logits4 = self.fc4(x)\n",
    "        return logits1, logits2, logits3, logits4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the weight of my model\n",
    "FILE1 = \"Task1_weights.pt\"\n",
    "FILE2 = \"Task2_weights.pt\"\n",
    "FILE3 = \"Task3_weights.pt\"\n",
    "root = \"/content/drive/MyDrive/HW5_model_weights\" # fill the path you store my weight\n",
    "# Load weight\n",
    "model1 = Mymodel1()\n",
    "model1.load_state_dict(torch.load(f\"{root}/{FILE1}\"))\n",
    "model2 = Mymodel2()\n",
    "model2.load_state_dict(torch.load(f\"{root}/{FILE2}\"))\n",
    "model3 = Mymodel3()\n",
    "model3.load_state_dict(torch.load(f\"{root}/{FILE3}\"))\n",
    "\n",
    "# Should output a warning (pretrained is deprecated..)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(rows, prefix, root):\n",
    "    filenames = np.array([sample for sample in rows if sample[0].startswith(prefix)])\n",
    "    imgs = filenames[:, 0]\n",
    "    label = filenames[:, 1]\n",
    "    images = np.zeros(shape=(len(filenames), 64, 64, 3), dtype=np.uint8)\n",
    "    labels = np.zeros(shape=(len(filenames), len(label[0])), dtype=np.int32)\n",
    "    for i in trange(len(filenames)):\n",
    "        curr_img = cv2.imread(f\"{root}/{imgs[i]}\")\n",
    "        curr_img = cv2.resize(curr_img,  (64, 64))\n",
    "        images[i] = curr_img\n",
    "        if prefix == \"task1\":\n",
    "            curr_label = [class_index[x]-26 for x in label[i]]\n",
    "        else:\n",
    "            curr_label = [class_index[x] for x in label[i]]\n",
    "        labels[i] = np.array(curr_label)\n",
    "    return np.array(imgs), np.array(images), np.array(labels)\n",
    "class ImgDataset(Dataset):\n",
    "    def __init__(self, x_data, y_data, root, filenames, return_filename=False, prefix=\"task1\"):\n",
    "        x_data = x_data.astype('float32')\n",
    "        self.x_data = torch.from_numpy(x_data).permute(0, 3, 1, 2) # (N, 1, 64, 64)\n",
    "        self.y_data = torch.from_numpy(y_data) \n",
    "        self.filenames = filenames\n",
    "        self.return_filename = return_filename\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        if self.return_filename:\n",
    "            return self.x_data[index], self.filenames[index] \n",
    "        else:\n",
    "            return self.x_data[index], self.y_data[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = []\n",
    "with open(f'{TEST_PATH}/../sample_submission.csv', newline='') as csvfile:\n",
    "    for row in csv.reader(csvfile, delimiter=','):\n",
    "        test_data.append(row)\n",
    "\n",
    "csv_writer = csv.writer(open('submission.csv', 'w', newline=''))\n",
    "csv_writer.writerow([\"filename\", \"label\"])\n",
    "\n",
    "test_path, x_test, y_test = read_data(rows=test_data, prefix=\"task1\", root=TEST_PATH)\n",
    "test_ds1 = ImgDataset(x_data=x_test, y_data=y_test, root=TEST_PATH, filenames=test_path, return_filename=True, prefix=\"task1\")\n",
    "test_dl1 = DataLoader(test_ds1, batch_size=500, num_workers=2, drop_last=False, shuffle=False)\n",
    "\n",
    "test_path, x_test, y_test = read_data(rows=test_data, prefix=\"task2\", root=TEST_PATH)\n",
    "test_ds2 = ImgDataset(x_data=x_test, y_data=y_test, root=TEST_PATH, filenames=test_path, return_filename=True, prefix=\"task2\")\n",
    "test_dl2 = DataLoader(test_ds2, batch_size=500, num_workers=2, drop_last=False, shuffle=False)\n",
    "\n",
    "test_path, x_test, y_test = read_data(rows=test_data, prefix=\"task3\", root=TEST_PATH)\n",
    "test_ds3 = ImgDataset(x_data=x_test, y_data=y_test, root=TEST_PATH, filenames=test_path, return_filename=True, prefix=\"task3\")\n",
    "test_dl3 = DataLoader(test_ds3, batch_size=500, num_workers=2, drop_last=False, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_writer = csv.writer(open('submission.csv', 'w', newline=''))\n",
    "csv_writer.writerow([\"filename\", \"label\"])\n",
    "\n",
    "model1 = model1.to(device)\n",
    "model1.eval()\n",
    "for image, filenames in test_dl1:\n",
    "    image = image.to(device)\n",
    "    \n",
    "    pred = model1(image)\n",
    "    pred = torch.argmax(pred, dim=1)\n",
    "    \n",
    "    for i in range(len(filenames)):\n",
    "        curr_string = class_index_rev[pred[i].item()+26]\n",
    "#         print(f\"Write: {filenames[i]},{curr_string}\")\n",
    "        csv_writer.writerow([filenames[i], str(pred[i].item())])\n",
    "print(\"Task1: done\")\n",
    "\n",
    "\n",
    "model2 = model2.to(device)\n",
    "model2.eval()\n",
    "for image, filenames in test_dl2:\n",
    "    image = image.to(device)\n",
    "    \n",
    "    output = model2(image)\n",
    "    pred1 = torch.argmax(output[0], dim=1)\n",
    "    pred2 = torch.argmax(output[1], dim=1)\n",
    "    \n",
    "    for i in range(len(filenames)):\n",
    "        curr_string = class_index_rev[pred1[i].item()]+class_index_rev[pred2[i].item()]\n",
    "#         print(f\"Write: {filenames[i]},{curr_string}\")\n",
    "        csv_writer.writerow([filenames[i], curr_string])\n",
    "print(\"Task2: done\")\n",
    "\n",
    "model3 = model3.to(device)\n",
    "model3.eval()\n",
    "for image, filenames in test_dl3:\n",
    "    image = image.to(device)\n",
    "    \n",
    "    output = model3(image)\n",
    "    pred1 = torch.argmax(output[0], dim=1)\n",
    "    pred2 = torch.argmax(output[1], dim=1)\n",
    "    pred3 = torch.argmax(output[2], dim=1)\n",
    "    pred4 = torch.argmax(output[3], dim=1)\n",
    "    for i in range(len(filenames)):\n",
    "        curr_string = class_index_rev[pred1[i].item()]+class_index_rev[pred2[i].item()]+class_index_rev[pred3[i].item()]+class_index_rev[pred4[i].item()]\n",
    "#         print(f\"Write: {filenames[i]},{curr_string}\")\n",
    "        csv_writer.writerow([filenames[i], curr_string])\n",
    "print(\"Task3: done\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
